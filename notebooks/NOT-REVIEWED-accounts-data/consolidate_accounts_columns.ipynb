{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we can view all the many columns\n",
    "pd.options.display.max_columns = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the yaml of questions from the Brexit checker downloaded from\n",
    "# https://github.com/alphagov/finder-frontend/blob/master/app/lib/brexit_checker/questions.yaml\n",
    "with open(r'questions.yaml') as file:\n",
    "    questions_list = yaml.load(file, Loader=yaml.SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are four question types at the moment:\n",
    "# 'multiple', 'multiple_grouped', 'single', 'single_wrapped'\n",
    "set([question['type'] for question in questions_list['questions']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get BQ data, use OAuth to authenticate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow [these instructions](https://cloud.google.com/docs/authentication/end-user#end_user_authentication_example)\n",
    "\n",
    "This worked with OAuth Client `Suganya web client test`, which was created by:\n",
    "- From [this page](https://console.cloud.google.com/apis/credentials?project=govuk-bigquery-analytics) click `Create Credentials`\n",
    "- Choose OAuth Client ID\n",
    "- Application type = Web Application\n",
    "- added `http://localhost:8080` to authorised redirect URIs\n",
    "- click `Download JSON` to download client secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_auth_oauthlib import flow\n",
    "from google.cloud import bigquery\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOGLE_OAUTH_CLIENT_CREDENTIALS is the path to the BQ client secret should be set in .secrets file\n",
    "GOOGLE_OAUTH_CLIENT_CREDENTIALS = os.getenv('GOOGLE_OAUTH_CLIENT_CREDENTIALS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_browser = True\n",
    "#\n",
    "# The `launch_browser` boolean variable indicates if a local server is used\n",
    "# as the callback URL in the auth flow. A value of `True` is recommended,\n",
    "# but a local server does not work if accessing the application remotely,\n",
    "# such as over SSH or from a remote Jupyter notebook.\n",
    "\n",
    "appflow = flow.InstalledAppFlow.from_client_secrets_file(\n",
    "#     path to client secrets file\n",
    "    GOOGLE_OAUTH_CLIENT_CREDENTIALS,\n",
    "    scopes=['https://www.googleapis.com/auth/bigquery'])\n",
    "\n",
    "if launch_browser:\n",
    "    appflow.run_local_server()\n",
    "else:\n",
    "    appflow.run_console()\n",
    "\n",
    "credentials = appflow.credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client(project='govuk-account-analysis-db', credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accounts_transition_checker_data_sql = '''\n",
    "    SELECT * FROM\n",
    "    `govuk-account-analysis-db.daily.transition_checker`\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_transition_checker_df = client.query(get_accounts_transition_checker_data_sql).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_transition_checker_df.to_csv('raw_accounts_transition_checker_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work on questions with a single answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_single_answer_q(row_of_accounts_data, question_option_values):\n",
    "    \"\"\"\n",
    "    look at all the columns relating to a single-answer question (one columns per possible answer) and return the answer that was chosen\n",
    "    one_row: a row of accounts data (from a pandas dataframe)\n",
    "    question_option_values: for a single answer question, what values can the answer take?\n",
    "    \"\"\"\n",
    "    for table_value in question_option_values:\n",
    "        if row_of_accounts_data[table_value] == True:\n",
    "            return table_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_all_single_answer_questions(single_answer_questions_list, accounts_df, new_accounts_columns_dict):\n",
    "    \"\"\"\n",
    "    take a dataframe of checker responses, for questions that only want one answer, get all the potential answer columns,\n",
    "    bring the answers into one column for using later on, and drop the one-hot encoding style columns\n",
    "    single_answer_questions: list of the dictionaries describing each question that takes a single answer\n",
    "    accounts_df: pandas dataframe containing accounts data - the responses to the brexit checker questions\n",
    "    \"\"\"\n",
    "    for question in single_answer_questions_list:\n",
    "        question_key = question['key'] #\n",
    "        question_option_values = [option['value'].replace('-','_') for option in question['options']]\n",
    "        accounts_df[question_key] = accounts_df.apply(lambda x: collapse_single_answer_q(x, question_option_values), axis=1)\n",
    "#         drop those one-hot style columns for a narrower DF, could remove this if you want to keep them though\n",
    "#         print(question_option_values)\n",
    "        accounts_df = accounts_df.drop(question_option_values, axis=1)\n",
    "        new_accounts_columns_dict.update({question['key']: [question['key'],\n",
    "                                                            question['text'],\n",
    "                                                            'single answer',\n",
    "                                                            [option['label'] for option in question['options']],\n",
    "                                                            question_option_values]})\n",
    "    return accounts_df, new_accounts_columns_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at single-wrapped questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_all_single_wrapped_answer_questions(single_wrapped_questions_list, accounts_df, new_accounts_columns_dict):\n",
    "    \"\"\"\n",
    "    take a dataframe of checker responses, for questions that only want one answer, but then multiple follow ups,\n",
    "    get all the potential answer columns,\n",
    "    bring the mutually exclusive top-level answers into one column for using later on,\n",
    "    and drop the one-hot encoding style columns\n",
    "    single_wrapped_questions_list: list of the dictionaries describing each question that takes a single answer with multiple follow-ups\n",
    "    accounts_df: pandas dataframe containing accounts data - the responses to the brexit checker questions\n",
    "    \"\"\"\n",
    "    column_renaming_mapper = dict()\n",
    "    for question in single_wrapped_questions_list:\n",
    "        question_key = question['key']\n",
    "        question_option_values = []\n",
    "        for option in question['options']:\n",
    "            question_option_values.append(option['value'].replace('-','_'))\n",
    "            if 'options' in option:\n",
    "                for choice in option['options']:\n",
    "                    new_column_name = f\"{question_key}--{choice['value'].replace('-','_')}\"\n",
    "                    column_renaming_mapper.update(\n",
    "                        {choice['value'].replace('-','_'): new_column_name})\n",
    "                    new_accounts_columns_dict.update(\n",
    "                        {new_column_name: [question['key'],\n",
    "                                           question['text'],\n",
    "                                           'single wrapped - further options',\n",
    "                                           choice['label'],\n",
    "                                           ['True', 'None']]})\n",
    "        accounts_df[question_key] = accounts_df.apply(lambda x: collapse_single_answer_q(x, question_option_values), axis=1)\n",
    "#         drop those one-hot style columns for a narrower DF, could remove this if you want to keep them though\n",
    "#         print(question_option_values)\n",
    "        accounts_df = accounts_df.drop(question_option_values, axis=1)\n",
    "        new_accounts_columns_dict.update({question['key']: [question['key'],\n",
    "                                                            question['text'],\n",
    "                                                            'single wrapped - top level',\n",
    "                                                            [option['label'] for option in question['options']],\n",
    "                                                            question_option_values]})\n",
    "    accounts_df = accounts_df.rename(columns=column_renaming_mapper, errors=\"raise\")\n",
    "    return accounts_df, new_accounts_columns_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename multi-answer columns to add reference to the question asked?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_multiple_answer_questions(multiple_questions_list, accounts_df, new_accounts_columns_dict):\n",
    "    \"\"\"\n",
    "    take a dataframe of checker responses, for questions that can have multiple answers,\n",
    "    get all the potential answer columns and add the question key as a prefix\n",
    "    multiple_questions_list: list of the dictionaries describing each question that takes multiple answers\n",
    "    accounts_df: pandas dataframe containing accounts data - the responses to the brexit checker questions\n",
    "    \"\"\"\n",
    "    column_renaming_mapper = dict()\n",
    "    for question in multiple_questions_list:\n",
    "        question_key = question['key']\n",
    "        for choice in question['options']:\n",
    "            new_column_name = f\"{question_key}--{choice['value'].replace('-','_')}\"\n",
    "            column_renaming_mapper.update(\n",
    "                {choice['value'].replace('-','_'): new_column_name})\n",
    "            new_accounts_columns_dict.update(\n",
    "                {new_column_name: [question['key'],\n",
    "                                   question['text'],\n",
    "                                   'multiple',\n",
    "                                   choice['label'],\n",
    "                                   ['True', 'None']]})\n",
    "    accounts_df = accounts_df.rename(columns=column_renaming_mapper, errors=\"raise\")\n",
    "#         print(question_option_values)\n",
    "    return accounts_df, new_accounts_columns_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename multiple grouped answer columns to add reference to the question asked?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_multiple_grouped_answer_questions(multiple_grouped_questions_list, accounts_df, new_accounts_columns_dict):\n",
    "    \"\"\"\n",
    "    take a dataframe of checker responses, for questions that can have multiple (grouped)answers,\n",
    "    get all the potential answer columns and add the question key as a prefix\n",
    "    multiple_grouped_questions_list: list of the dictionaries describing each question that takes multiple grouped answers\n",
    "    accounts_df: pandas dataframe containing accounts data - the responses to the brexit checker questions\n",
    "    \"\"\"\n",
    "    column_renaming_mapper = dict()\n",
    "    for question in multiple_grouped_questions_list:\n",
    "        question_key = question['key']\n",
    "        question_option_values = []\n",
    "        for option in question['options']:\n",
    "            if 'options' in option:\n",
    "                for choice in option['options']:\n",
    "                    new_column_name = f\"{question_key}--{choice['value'].replace('-','_')}\"\n",
    "                    column_renaming_mapper.update(\n",
    "                        {choice['value'].replace('-','_'): new_column_name})\n",
    "                    new_accounts_columns_dict.update(\n",
    "                        {new_column_name: [question['key'],\n",
    "                                           question['text'],\n",
    "                                           'multiple grouped',\n",
    "                                           choice['label'],\n",
    "                                           ['True', 'None']]})\n",
    "            \n",
    "    accounts_df = accounts_df.rename(columns=column_renaming_mapper, errors=\"raise\")\n",
    "    return accounts_df, new_accounts_columns_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neaten_accounts_df(questions_list, accounts_df):\n",
    "#     check we only have expected question types\n",
    "    expected_question_types = set([question['type'] for question in questions_list['questions']]) \n",
    "    if len({'multiple', 'multiple_grouped', 'single', 'single_wrapped'} - expected_question_types) > 1:\n",
    "            raise ValueError('unknown question types in questions_list that we cannot process')\n",
    "    \n",
    "    new_accounts_columns_dict = dict()\n",
    "            \n",
    "    single_answer_questions = [question for question in questions_list['questions'] if question['type'] == 'single']\n",
    "    accounts_df, new_accounts_columns_dict = collapse_all_single_answer_questions(\n",
    "        single_answer_questions, accounts_df, new_accounts_columns_dict)\n",
    "\n",
    "    single_wrapped_answer_questions = [question for question in questions_list['questions'] if question['type'] == 'single_wrapped']\n",
    "    accounts_df, new_accounts_columns_dict = collapse_all_single_wrapped_answer_questions(\n",
    "        single_wrapped_answer_questions, accounts_df, new_accounts_columns_dict)\n",
    "\n",
    "    multiple_answer_questions = [question for question in questions_list['questions'] if question['type'] == 'multiple']\n",
    "    accounts_df, new_accounts_columns_dict = rename_multiple_answer_questions(\n",
    "        multiple_answer_questions, accounts_df, new_accounts_columns_dict)\n",
    "\n",
    "    multiple_grouped_answer_questions = [question for question in questions_list['questions'] if question['type'] == 'multiple_grouped']\n",
    "    accounts_df, new_accounts_columns_dict = rename_multiple_grouped_answer_questions(\n",
    "        multiple_grouped_answer_questions, accounts_df, new_accounts_columns_dict)\n",
    "    return accounts_df, new_accounts_columns_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neater_accounts_data, new_schema = neaten_accounts_df(questions_list, accounts_transition_checker_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neater_accounts_data.to_csv('neater_accounts_transition_checker_date.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_schema_df = pd.DataFrame.from_dict(new_schema, orient='index', \n",
    "                       columns=['question-key', 'question-text', 'question type', 'options', 'values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_schema_df.to_csv('new_schema.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neater_accounts_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_schema_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
