{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity subclasses\n",
    "\n",
    "There are lots of entities in government that are subclasses of one another.\n",
    "\n",
    "By this I mean that, for example, a \"child passport\" is a subclass of \"passport\" - it is a more specific form of a passport and has siblings like \"adult passport\", \"horse passport\", \"pet passport\" etc etc\n",
    "\n",
    "By extracting these we can get a better understanding of how entities relate to another\n",
    "\n",
    "We can also help users with this information, both in terms of actually understanding that a search like \"passport for my daughter\" actually relates to \"child passport\" (well...probably, a daughter can technically be any age - but we do know that a horse or pet passport is not related) so we can improve search in this manner.\n",
    "\n",
    "We can also use it to provide handy hints for users who are doing vague searches. For example, if someone types in \"passport\" we can suggest \"adult passport\", \"child passport\" etc as a way of helping them refine what they mean and thus get better results\n",
    "\n",
    "The results from this notebook are quite good but some refinement is needed. It's also _painfully_ slow - taking more than 24 hours on my machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import os\n",
    "from py2neo import Graph\n",
    "import sys\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# govuk-language-model uses the environment variable to set where the data for the model is\n",
    "# I have the data in that folder, you might have it elsewhere. Contact me if you're not sure what the data\n",
    "# is and/or how it all fits together\n",
    "os.environ['MODEL_FILE_PATH'] = '../../govuk-knowledge-graph/data'\n",
    "# Requires govuk-language-model\n",
    "sys.path.append(\"../../govuk-language-model\")\n",
    "from sagemaker.container.govner.govner import GovNER\n",
    "ner = GovNER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "html_content_dir_path = \"/Users/oscarwyatt/govuk/govuk-knowledge-extractor/govuk-production-mirror-replica\"\n",
    "preprocessed_content_store_path = \"/Users/oscarwyatt/govuk/govuk-knowledge-graph/data/preprocessed_content_store_070920.csv.gz\"\n",
    "\n",
    "all_content_items = pd.read_csv(preprocessed_content_store_path, sep=\"\\t\", compression=\"gzip\",\n",
    "                                         low_memory=False)\n",
    "\n",
    "print(\"Finished reading from the preprocessed content store!\")\n",
    "\n",
    "mainstream_content = all_content_items[all_content_items['publishing_app'] == 'publisher']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Page:\n",
    "    def __init__(self, content_item, html_content_dir_path):\n",
    "        self.content_item = content_item\n",
    "        self.html_content_dir_path = html_content_dir_path\n",
    "        self.texts = self._extract_texts()\n",
    "        \n",
    "    def base_path(self):\n",
    "        return self.content_item['base_path']\n",
    "    \n",
    "    def html_file_path(self):\n",
    "        return f\"{self.html_content_dir_path}{self.base_path()}.html\"\n",
    "        \n",
    "    def _extract_texts(self):\n",
    "        if os.path.exists(self.html_file_path()):\n",
    "            # I have an old copy of the mirrors so sometimes the file won't exist\n",
    "            with open(self.html_file_path(), \"r\") as html_file:\n",
    "                html = html_file.read()\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                for tag in ['b', 'i', 'u', 'a', 'abbr']:\n",
    "                    for match in soup.findAll(tag):\n",
    "                        match.replaceWithChildren()\n",
    "                        # If we don't extract them, the old tags stick\n",
    "                        # around and mess up the soup.strings call\n",
    "                        # match.extract()\n",
    "                [x.extract() for x in soup.findAll('script')]\n",
    "                soup = BeautifulSoup(str(soup), 'html.parser')\n",
    "                texts = list(soup.strings)\n",
    "                texts = [text for text in texts if text != '\\n']\n",
    "                return texts\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = []\n",
    "for index, content_item in mainstream_content.iterrows():\n",
    "    pages.append(Page(content_item, html_content_dir_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subclasses = []\n",
    "for page in pages:\n",
    "    subclasses += get_subclasses(page.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subclasses(texts):\n",
    "    subclasses = []\n",
    "    for text in texts:\n",
    "        subclasses += get_subclasses_for_text(text)\n",
    "    return subclasses\n",
    "\n",
    "\n",
    "def get_subclasses_for_text(text):\n",
    "    extracted_matches = ner.predictor.predict(text)\n",
    "    ner._create_entity_dict(extracted_matches)\n",
    "    entities = {}\n",
    "    last_label = None\n",
    "    tokens_with_label = []\n",
    "    extracted_subclasses = []\n",
    "    for i, (left_to_right_tokens, left_to_right_labels) in enumerate(extracted_matches):\n",
    "        tokens = left_to_right_tokens.copy()\n",
    "        tokens.reverse()\n",
    "        labels = left_to_right_labels.copy()\n",
    "        labels.reverse()\n",
    "        last_entity = None\n",
    "        for token, label in zip(tokens, labels):\n",
    "            if label != \"O\" and label != '[SEP]':\n",
    "                # could be a subclass\n",
    "                tokens_with_label.append(token)\n",
    "                if len(tokens_with_label) > 1:\n",
    "                    un_reversed_tokens = tokens_with_label.copy()\n",
    "                    un_reversed_tokens.reverse()\n",
    "                    entire_entity = \" \".join(un_reversed_tokens)\n",
    "                    extracted_subclasses.append([last_entity, entire_entity])\n",
    "                    last_entity = entire_entity\n",
    "                else:\n",
    "                    last_entity = token\n",
    "            else:\n",
    "                tokens_with_label = []\n",
    "                last_entity = None\n",
    "            last_label = label\n",
    "            last_token = token\n",
    "    return extracted_subclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_subclasses = {}\n",
    "for subclass in subclasses:\n",
    "    unique_subclasses[f\"{subclass[0].lower()} - {subclass[1].lower()}\"] = subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_subclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_subclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It takes a long time to run so save them to disk\n",
    "\n",
    "with open('subclasses.json', 'w') as json_file:\n",
    "    json.dump(unique_subclasses, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load subclasses from file and insert into graph\n",
    "\n",
    "If you're coming back later or with a pregenerated file, you can start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "with open('subclasses.json', 'r') as json_file:\n",
    "    loaded_unique_subclasses = json.load(json_file)\n",
    "print(len(loaded_unique_subclasses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This finds subclass entries where there is an entity for both sides already in the graph and if so, creates a relationship between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = os.environ.get('REMOTE_NEO4J_URL')\n",
    "user = os.environ.get('NEO4J_USER')\n",
    "password = os.environ.get('NEO4J_PASSWORD')\n",
    "graph = Graph(host=host, user='neo4j', password = password, secure=True)\n",
    "\n",
    "has_both = []\n",
    "for parent, child in loaded_unique_subclasses.items():\n",
    "    try:\n",
    "        entities = graph.run(\"MATCH (a:Entity{name: '\" + parent + \"'}) WITH a OPTIONAL MATCH (b:Entity{name: '\" + child + \"'}) return a.name as parent, b.name as child\").data()\n",
    "        print(entities)\n",
    "        if any(entities) and entities[0]['parent'] and entities[0]['child']:\n",
    "            has_both.append([parent, child])\n",
    "            # NB: I haven't run this query so it may require debugging\n",
    "            graph.run(\"MATCH (parent:Entity{name: '\" + parent + \"'}) WITH parent OPTIONAL MATCH (child:Entity{name: '\" + child + \"'} CREATE (parent)-[:HAS_SUBCLASS]->(child) CREATE (child)-[:HAS_SUPERCLASS]->(parent)\")\n",
    "    except ClientError:\n",
    "        next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_both"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
